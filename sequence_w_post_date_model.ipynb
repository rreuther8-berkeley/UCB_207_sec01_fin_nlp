{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c012ad34-0e2d-4e51-bb7e-1efa0a17defb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:15:55.783065: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# tf and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, losses\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    GlobalAveragePooling1D,\n",
    "    Dropout,\n",
    "    TextVectorization,\n",
    "    Input,\n",
    "    Conv1D,\n",
    "    LSTM,\n",
    "    MaxPooling1D,\n",
    "    Bidirectional,\n",
    "    Concatenate,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050b113-b9e2-45ef-99be-5ef0bc10be5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9547d168-9089-473e-9516-6124bfa52e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_model(model):\n",
    "    display(model.layers)\n",
    "    display(model.summary())\n",
    "\n",
    "    # Retrieve the embeddings layer, which itself is wrapped in a list.\n",
    "    embeddings = model.layers[1].get_weights()[0]\n",
    "    print('-'*100)\n",
    "    display(\"Embeddings layer - shape: \", embeddings.shape)\n",
    "    print('-'*100)\n",
    "    display(\"Embeddings layer - parameter matrix (before training): \", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1161982-b3ac-4aa0-9925-ebf88d733c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    X_train = pd.read_csv('./data/final/X_train.csv')\n",
    "    y_train = pd.read_csv('./data/final/y_train.csv')\n",
    "    X_val = pd.read_csv('./data/final/X_val.csv')\n",
    "    y_val = pd.read_csv('./data/final/y_val.csv')\n",
    "    X_test = pd.read_csv('./data/final/X_test.csv')\n",
    "    y_test = pd.read_csv('./data/final/y_test.csv')\n",
    "    \n",
    "    train_not_na_indices = (X_train['fulltext'].notna())\n",
    "    val_not_na_indices = (X_val['fulltext'].notna())\n",
    "    test_not_na_indices = (X_test['fulltext'].notna())\n",
    "    \n",
    "    X_train = X_train[train_not_na_indices]\n",
    "    X_val = X_val[val_not_na_indices]\n",
    "    X_test = X_test[test_not_na_indices]\n",
    "    \n",
    "    y_train = y_train[train_not_na_indices]\n",
    "    y_val = y_val[val_not_na_indices]\n",
    "    y_test = y_test[test_not_na_indices]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c5d5d0-1905-40bb-9c60-933bfa063253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vectorization_layer(df, column, max_tokens=10000, output_sequence_length=250, embedding_dim=16):\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        max_tokens=max_tokens,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=output_sequence_length)\n",
    "\n",
    "    df[column] = df[column].astype(str)\n",
    "    vectorize_layer.adapt(df[column].values)\n",
    "\n",
    "    return vectorize_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b470ea7a-193b-4391-809a-0a8fc78a46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorization_layer_ngrams(df, column, max_tokens=10000, output_sequence_length=250, embedding_dim=16, ngrams=3):\n",
    "    vectorize_layer = layers.TextVectorization(\n",
    "        max_tokens=max_tokens,\n",
    "        ngrams=ngrams,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=output_sequence_length)\n",
    "\n",
    "    df[column] = df[column].astype(str)\n",
    "    vectorize_layer.adapt(df[column].values)\n",
    "\n",
    "    return vectorize_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564b7a2d-f7c2-4606-a710-a71559c4aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = read_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3da75c-0cf4-4c15-a54c-f2d6c8a640a4",
   "metadata": {},
   "source": [
    "# Text Tokenization and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb83eb9-ed9e-4309-bbee-8f2c57f685ce",
   "metadata": {},
   "source": [
    "### Convert the fulltext into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ffc8dbc-b267-4a67-be24-05c872afbf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:16:01.651284: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "text_data = tf.constant(X_train['fulltext'].values)\n",
    "text_data_val = tf.constant(X_val['fulltext'].values)\n",
    "text_data_test = tf.constant(X_test['fulltext'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899fbdb8-5424-4d0f-aea8-4f2db4bd0069",
   "metadata": {},
   "source": [
    "### Get vectorization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c38723-a285-4603-a648-5062882f42a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorize_layer = get_vectorization_layer(X_train, 'fulltext')\n",
    "vectorize_layer_3_ngrams = get_vectorization_layer_ngrams(X_train, 'fulltext')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44b463-b392-489e-8d88-6d8283bf3aae",
   "metadata": {},
   "source": [
    "### Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d52369a7-1a2b-43e3-bf0a-3d1c15b9dfc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_text = vectorize_layer(text_data)\n",
    "vectorized_text_val = vectorize_layer(text_data_val)\n",
    "vectorized_text_test = vectorize_layer(text_data_test)\n",
    "\n",
    "vectorized_text_3_ngrams = vectorize_layer_3_ngrams(text_data)\n",
    "vectorized_text_val_3_ngrams = vectorize_layer_3_ngrams(text_data_val)\n",
    "vectorized_text_test_3_ngrams = vectorize_layer_3_ngrams(text_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1880416-ff6b-41ad-a09b-ec3e87a56f07",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4fbe36-c1e8-46d1-acc5-dafb529cd7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_time_fields(X_train, X_val, X_test):\n",
    "    X_test['created'] = pd.to_datetime(X_test['created'])\n",
    "    X_train['created'] = pd.to_datetime(X_train['created'])\n",
    "    X_val['created'] = pd.to_datetime(X_val['created'])\n",
    "\n",
    "    # Create the new columns\n",
    "    X_test['hour_of_day'] = X_test['created'].dt.hour\n",
    "    X_test['day_of_week'] = X_test['created'].dt.dayofweek\n",
    "    \n",
    "\n",
    "    X_train['hour_of_day'] = X_train['created'].dt.hour\n",
    "    X_train['day_of_week'] = X_train['created'].dt.dayofweek\n",
    "\n",
    "    X_val['hour_of_day'] = X_val['created'].dt.hour\n",
    "    X_val['day_of_week'] = X_val['created'].dt.dayofweek\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "X_train, X_val, X_test = create_time_fields(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b869ee3-8a5b-41e3-9b8f-6b1ca593b923",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multifeature Model 1 - fulltext and hour_of_day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45477179-4208-496d-8235-95a86e7b4e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_multifeature_model(max_tokens=10000, output_sequence_length=250, embedding_dim=16):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    text_input = Input(shape=(output_sequence_length,), name=\"fulltext\")\n",
    "    dense_input = Input(shape=(1,), dtype=tf.float32, name='hour_of_day')\n",
    "    \n",
    "    embeddings = Embedding(input_dim=max_tokens, output_dim=embedding_dim, input_length=output_sequence_length)(text_input)\n",
    "    dense_hidden = Dense(32, activation='relu')(dense_input)\n",
    "    dense_hidden = Dropout(0.5)(dense_hidden)\n",
    "    \n",
    "    flattened_text = tf.keras.layers.GlobalAveragePooling1D()(embeddings)\n",
    "    combined = Concatenate()([flattened_text, dense_hidden])\n",
    "    \n",
    "    x = Dense(64, activation='relu')(combined)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    \n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=[text_input, dense_input], outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error','accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8796b134-f5f0-481c-a646-cfdb09b3d44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 131s 26ms/step - loss: 1.7156 - mean_absolute_error: 0.3051 - accuracy: 0.0000e+00 - val_loss: 0.7083 - val_mean_absolute_error: 0.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 126s 25ms/step - loss: 1.4927 - mean_absolute_error: 0.1480 - accuracy: 0.0000e+00 - val_loss: 0.7059 - val_mean_absolute_error: 0.1316 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 99s 20ms/step - loss: 1.4952 - mean_absolute_error: 0.1425 - accuracy: 0.0000e+00 - val_loss: 0.7062 - val_mean_absolute_error: 0.1249 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.715566</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708297</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.492716</td>\n",
       "      <td>0.148048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>0.131617</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.495243</td>\n",
       "      <td>0.142529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.706152</td>\n",
       "      <td>0.124943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  mean_absolute_error  accuracy  val_loss  val_mean_absolute_error  \\\n",
       "0  1.715566             0.305104       0.0  0.708297                 0.174849   \n",
       "1  1.492716             0.148048       0.0  0.705912                 0.131617   \n",
       "2  1.495243             0.142529       0.0  0.706152                 0.124943   \n",
       "\n",
       "   val_accuracy  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_multifeature = build_multifeature_model()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "history_1_mf = model_1_multifeature.fit(\n",
    "    {\n",
    "        'fulltext': vectorized_text[:10000],\n",
    "        'hour_of_day': X_train['hour_of_day'][:10000],\n",
    "    },\n",
    "    y_train[:10000],\n",
    "    epochs=10,\n",
    "    batch_size=2,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=({\n",
    "        'fulltext': vectorized_text_val,\n",
    "        'hour_of_day': X_val['hour_of_day']\n",
    "    }, y_val)\n",
    ")\n",
    "\n",
    "hist_1_mf = pd.DataFrame(history_1_mf.history)\n",
    "hist_1_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d042aedb-23e2-4807-802f-647ed2e8f364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_1_mf.to_csv('hist_1_mf.csv')\n",
    "model_1_multifeature.save(\"model_1_multifeature.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0205b9-cf28-4072-86fc-31f1e3e2467f",
   "metadata": {},
   "source": [
    "# Multifeature Model 2 - fulltext, hour_of_day, day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b949dd68-3e2f-4deb-b69a-26392170edd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_multifeature_model_2(max_tokens=10000, output_sequence_length=250, embedding_dim=16):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    text_input = Input(shape=(output_sequence_length,), name=\"fulltext\")\n",
    "    dense_input_1 = Input(shape=(1,), dtype=tf.float32, name='hour_of_day')\n",
    "    dense_input_2 = Input(shape=(1,), dtype=tf.float32, name='day_of_week')\n",
    "    \n",
    "    dense_hidden_1 = Dense(32, activation='relu')(dense_input_1)\n",
    "    dense_hidden_1 = Dropout(0.5)(dense_hidden_1)\n",
    "\n",
    "    dense_hidden_2 = Dense(32, activation='relu')(dense_input_2)\n",
    "    dense_hidden_2 = Dropout(0.5)(dense_hidden_2)\n",
    "\n",
    "    embeddings = Embedding(input_dim=max_tokens, output_dim=embedding_dim, input_length=output_sequence_length)(text_input)\n",
    "    flattened_text = tf.keras.layers.GlobalAveragePooling1D()(embeddings)\n",
    "    combined = Concatenate()([flattened_text, dense_hidden_1, dense_hidden_2])\n",
    "    \n",
    "    x = Dense(64, activation='relu')(combined)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    \n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=[text_input, dense_input_1, dense_input_2], outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error','accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dba0d35-c327-4a0a-8833-87bb35b25977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 115s 23ms/step - loss: 1.6027 - mean_absolute_error: 0.2405 - accuracy: 0.0000e+00 - val_loss: 0.7081 - val_mean_absolute_error: 0.1735 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 103s 21ms/step - loss: 1.4932 - mean_absolute_error: 0.1440 - accuracy: 0.0000e+00 - val_loss: 0.7063 - val_mean_absolute_error: 0.1481 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 224s 45ms/step - loss: 1.4906 - mean_absolute_error: 0.1382 - accuracy: 0.0000e+00 - val_loss: 0.7057 - val_mean_absolute_error: 0.1466 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 185s 37ms/step - loss: 1.4945 - mean_absolute_error: 0.1393 - accuracy: 0.0000e+00 - val_loss: 0.7018 - val_mean_absolute_error: 0.1092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 1.4863 - mean_absolute_error: 0.1398 - accuracy: 0.0000e+00 - val_loss: 0.6903 - val_mean_absolute_error: 0.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 117s 23ms/step - loss: 1.4528 - mean_absolute_error: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.6342 - val_mean_absolute_error: 0.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 1.3989 - mean_absolute_error: 0.1215 - accuracy: 0.0000e+00 - val_loss: 0.6199 - val_mean_absolute_error: 0.1025 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 126s 25ms/step - loss: 1.3900 - mean_absolute_error: 0.1275 - accuracy: 0.0000e+00 - val_loss: 0.6331 - val_mean_absolute_error: 0.1047 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.602742</td>\n",
       "      <td>0.240505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708123</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493185</td>\n",
       "      <td>0.144040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.706267</td>\n",
       "      <td>0.148054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.490582</td>\n",
       "      <td>0.138202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705716</td>\n",
       "      <td>0.146565</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.494459</td>\n",
       "      <td>0.139251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701792</td>\n",
       "      <td>0.109185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.486307</td>\n",
       "      <td>0.139756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.123022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.452848</td>\n",
       "      <td>0.134004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634230</td>\n",
       "      <td>0.131956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.398926</td>\n",
       "      <td>0.121493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619879</td>\n",
       "      <td>0.102525</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.390015</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.104673</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  mean_absolute_error  accuracy  val_loss  val_mean_absolute_error  \\\n",
       "0  1.602742             0.240505       0.0  0.708123                 0.173508   \n",
       "1  1.493185             0.144040       0.0  0.706267                 0.148054   \n",
       "2  1.490582             0.138202       0.0  0.705716                 0.146565   \n",
       "3  1.494459             0.139251       0.0  0.701792                 0.109185   \n",
       "4  1.486307             0.139756       0.0  0.690323                 0.123022   \n",
       "5  1.452848             0.134004       0.0  0.634230                 0.131956   \n",
       "6  1.398926             0.121493       0.0  0.619879                 0.102525   \n",
       "7  1.390015             0.127477       0.0  0.633122                 0.104673   \n",
       "\n",
       "   val_accuracy  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "5           0.0  \n",
       "6           0.0  \n",
       "7           0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_multifeature = build_multifeature_model_2()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "history_2_mf = model_2_multifeature.fit(\n",
    "    {\n",
    "        'fulltext': vectorized_text[:10000],\n",
    "        'hour_of_day': X_train['hour_of_day'][:10000],\n",
    "        'day_of_week': X_train['day_of_week'][:10000],\n",
    "    },\n",
    "    y_train[:10000],\n",
    "    epochs=10,\n",
    "    batch_size=2,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=({\n",
    "        'fulltext': vectorized_text_val,\n",
    "        'hour_of_day': X_val['hour_of_day'],\n",
    "        'day_of_week': X_val['day_of_week']\n",
    "    }, y_val)\n",
    ")\n",
    "\n",
    "hist_2_mf = pd.DataFrame(history_2_mf.history)\n",
    "hist_2_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b2797e-461d-4372-8a45-0adcb73e056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2_multifeature.save(\"model_2_multifeature.h5\")\n",
    "hist_2_mf.to_csv('hist_2_mf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3b40e-ccea-44cd-88e4-fa75eb8fa89b",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1abed2b-b50b-4966-97bd-adf99485930c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.715566</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708297</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.492716</td>\n",
       "      <td>0.148048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705912</td>\n",
       "      <td>0.131617</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.495243</td>\n",
       "      <td>0.142529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.706152</td>\n",
       "      <td>0.124943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  mean_absolute_error  accuracy  val_loss  val_mean_absolute_error  \\\n",
       "0  1.715566             0.305104       0.0  0.708297                 0.174849   \n",
       "1  1.492716             0.148048       0.0  0.705912                 0.131617   \n",
       "2  1.495243             0.142529       0.0  0.706152                 0.124943   \n",
       "\n",
       "   val_accuracy  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_1_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc9e6ab0-90e7-4d48-8225-a25d39450da1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.602742</td>\n",
       "      <td>0.240505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708123</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493185</td>\n",
       "      <td>0.144040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.706267</td>\n",
       "      <td>0.148054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.490582</td>\n",
       "      <td>0.138202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705716</td>\n",
       "      <td>0.146565</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.494459</td>\n",
       "      <td>0.139251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701792</td>\n",
       "      <td>0.109185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.486307</td>\n",
       "      <td>0.139756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.123022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.452848</td>\n",
       "      <td>0.134004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634230</td>\n",
       "      <td>0.131956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.398926</td>\n",
       "      <td>0.121493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619879</td>\n",
       "      <td>0.102525</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.390015</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.104673</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  mean_absolute_error  accuracy  val_loss  val_mean_absolute_error  \\\n",
       "0  1.602742             0.240505       0.0  0.708123                 0.173508   \n",
       "1  1.493185             0.144040       0.0  0.706267                 0.148054   \n",
       "2  1.490582             0.138202       0.0  0.705716                 0.146565   \n",
       "3  1.494459             0.139251       0.0  0.701792                 0.109185   \n",
       "4  1.486307             0.139756       0.0  0.690323                 0.123022   \n",
       "5  1.452848             0.134004       0.0  0.634230                 0.131956   \n",
       "6  1.398926             0.121493       0.0  0.619879                 0.102525   \n",
       "7  1.390015             0.127477       0.0  0.633122                 0.104673   \n",
       "\n",
       "   val_accuracy  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "5           0.0  \n",
       "6           0.0  \n",
       "7           0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_2_mf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61e509-d2a8-47d7-9e65-2ec827ca4957",
   "metadata": {},
   "source": [
    "# Model Losses (Train and Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7adc8ec-9322-4a7e-9e78-8a14c0d27e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_model(model, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    train_loss_mse, train_mae, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "    val_loss_mse, val_mae, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "    test_loss_mse, test_mae, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return {\n",
    "        \"train\": {\"mse\":train_loss_mse,\"mae\":train_mae,\"acc\":train_acc},\n",
    "        \"val\": {\"mse\":val_loss_mse,\"mae\":val_mae,\"acc\":val_acc},\n",
    "        \"test\": {\"mse\":test_loss_mse,\"mae\":test_mae,\"acc\":test_acc},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2d5b7b8-316a-42fd-a640-6131d48a3f9d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:25:32.804751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-31 17:25:32.807242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-31 17:25:32.811232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-31 17:25:33.154016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-31 17:25:33.155643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-31 17:25:33.158217: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-31 17:25:33.322687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-31 17:25:33.376827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-31 17:25:33.378235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-31 17:25:33.380467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model_2_saved = tf.keras.models.load_model('model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45e1a068-d84d-4fae-9aaa-322f4dabc326",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:27:26.126366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-31 17:27:26.128360: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-31 17:27:26.131305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-31 17:32:10.507156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-31 17:32:10.509124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-31 17:32:10.512553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-31 17:32:10.699845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-31 17:32:10.783456: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-31 17:32:10.786018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-31 17:32:10.788058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model_2_eval = validate_model(model_2_saved ,vectorized_text, y_train, vectorized_text_val, y_val, vectorized_text_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54a8dfd1-4745-47a0-92b0-5331b1398942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.860489</td>\n",
       "      <td>0.098758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>0.609747</td>\n",
       "      <td>0.104846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.284968</td>\n",
       "      <td>0.083762</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mse       mae  acc\n",
       "train  0.860489  0.098758  0.0\n",
       "val    0.609747  0.104846  0.0\n",
       "test   0.284968  0.083762  0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_2_eval).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8572194e-771f-474f-8e8e-09ca6989c6fd",
   "metadata": {},
   "source": [
    "Model 2 performed the best in terms of validation dataset loss, which calculated as the mean squared error.\n",
    "\n",
    "Model 2 - Validation Loss after 5 Epochs - 2145500.25\n",
    "Model 3 - Validation Loss after 3 Epochs - 2365950.75\n",
    "Model 4 - Validation Loss after 4 Epochs - 2463587.00\n",
    "Model 5 - Validation Loss after 5 Epochs - 2465304.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae30b12-a671-4611-ad85-1e7565a364f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75e35b-f237-46f2-9f6b-7bfec32289fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb09a9e-c2f4-49e0-a86a-405e2cd31273",
   "metadata": {},
   "source": [
    "# End of file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f819b9-4d42-4fbf-bf2d-c0ffd4809515",
   "metadata": {},
   "source": [
    "Sources:\n",
    "* https://stackoverflow.com/questions/73878049/how-do-you-convert-the-pandas-dataframe-to-tensorflow-python-data-ops-dataset-op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9e68a-d697-4c41-b9c1-3dfaa36d33ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
