{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71cf287a-2d8c-4984-8954-77755f2d0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import string\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890ed871-8986-46bf-bcf8-4c44b0303725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim  \n",
    "#from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "556933f6-4012-426b-a512-aee9862df8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db896e2-6702-4623-97a5-83e9f8a4423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9374d5b-c032-4b16-a818-232faddca78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec422ccf-6700-4cf3-bc88-1a58f650911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= pd.read_csv(cwd+'/data/final/X_train.csv')\n",
    "y_train= pd.read_csv(cwd+'/data/final/y_train.csv')\n",
    "\n",
    "X_val= pd.read_csv(cwd+'/data/final/X_val.csv')\n",
    "y_val= pd.read_csv(cwd+'/data/final/y_val.csv')\n",
    "\n",
    "X_test= pd.read_csv(cwd+'/data/final/X_test.csv')\n",
    "y_test= pd.read_csv(cwd+'/data/final/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ad94cb2-3a8c-4e6f-a409-3a78089ba0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['all_words']=X_train['title']+' '+ X_train['selftext']\n",
    "X_test['all_words']=X_test['title']+' '+ X_test['selftext']\n",
    "X_val['all_words']=X_val['title']+' '+ X_val['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a79353f1-289a-4cf8-8ca4-2a080f3c78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train=X_train['engagement_score_std']\n",
    "y_val=X_val['engagement_score_std']\n",
    "y_test=X_test['engagement_score_std']\n",
    "\n",
    "X_train=X_train[['all_words']]\n",
    "X_val=X_val[['all_words']]\n",
    "X_test=X_test[['all_words']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5711620-3719-4391-bc50-2de37078911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing:\n",
    "# lowercases, tokenizes\n",
    "X_train['all_words_tkn'] =X_train['all_words'].apply(simple_preprocess)\n",
    "X_val['all_words_tkn'] =X_val['all_words'].apply(simple_preprocess)\n",
    "X_test['all_words_tkn'] =X_test['all_words'].apply(simple_preprocess)\n",
    "\n",
    "#remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "add_stopwords={} #placeholder\n",
    "stop_words.update(add_stopwords)\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def stpout(lst):\n",
    "    return [word for word in lst if word not in stop_words]\n",
    "\n",
    "X_train['all_words_tkn']  =X_train['all_words_tkn'].apply(stpout)\n",
    "X_train['all_words_lemm']=X_train['all_words_tkn'].apply(lambda x: [lmtzr.lemmatize(word) for word in x])\n",
    "\n",
    "X_val['all_words_tkn']  =X_val['all_words_tkn'].apply(stpout)\n",
    "X_val['all_words_lemm']=X_val['all_words_tkn'].apply(lambda x: [lmtzr.lemmatize(word) for word in x])\n",
    "\n",
    "X_test['all_words_tkn']  =X_test['all_words_tkn'].apply(stpout)\n",
    "X_test['all_words_lemm']=X_test['all_words_tkn'].apply(lambda x: [lmtzr.lemmatize(word) for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8197b014-b4a1-4b8a-9686-8a68511d57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['all_words_lemm']=X_train['all_words_lemm'].str.join(',').str.replace(',', ' ')\n",
    "X_val['all_words_lemm']=X_val['all_words_lemm'].str.join(',').str.replace(',', ' ')\n",
    "X_test['all_words_lemm']=X_test['all_words_lemm'].str.join(',').str.replace(',', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f4c9c-68af-4643-be10-da1602c55d12",
   "metadata": {},
   "source": [
    "max_df float or int, default=1.0\n",
    "When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "min_df float or int, default=1\n",
    "When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "936e5ebe-dd17-478a-83d8-353454bbd4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from the training data using a sparse vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=100)\n",
    "X_train_vector = vectorizer.fit_transform(X_train['all_words_lemm'])\n",
    "\n",
    "\n",
    "# Extracting features from the test data using the same vectorizer\n",
    "X_val_vector = vectorizer.transform(X_val['all_words_lemm'])\n",
    "X_test_vector = vectorizer.transform(X_test['all_words_lemm'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7fd3997-1749-4232-a816-bfb1f730c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg = LinearRegression().fit(X_train_vector, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ebe4669-e32e-44a8-a8c8-e179291510d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train set 0.7749349832951868\n",
      "MSE for val set 0.7331650094495095\n",
      "MSE for test set 0.3931705166238747\n"
     ]
    }
   ],
   "source": [
    "y_train_pred= reg.predict(X_train_vector)\n",
    "y_test_pred= reg.predict(X_test_vector)\n",
    "y_val_pred= reg.predict(X_val_vector)\n",
    "\n",
    "MSE_train = mean_squared_error(y_train,y_train_pred)\n",
    "MSE_val = mean_squared_error(y_val,y_val_pred)\n",
    "MSE_test = mean_squared_error(y_test,y_test_pred)\n",
    "\n",
    "print('MSE for train set', MSE_train)\n",
    "print('MSE for val set', MSE_val)\n",
    "print('MSE for test set', MSE_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fba16-82ec-4167-80f8-b1bddc447384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
